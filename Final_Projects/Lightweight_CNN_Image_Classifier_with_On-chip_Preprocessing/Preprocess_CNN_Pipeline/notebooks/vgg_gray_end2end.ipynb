{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End FINN Flow for the VGG-like 1-Channel Convolutional Net\n",
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the helper function `showInNetron` to show the ONNX model at the current transformation step. The Netron displays are interactive, but they only work when running the notebook actively and not on GitHub (i.e. if you are viewing this on GitHub you'll only see blank squares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "    \n",
    "build_dir = \"/workspace/finn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FINN Import and Tidy-Up\n",
    "\n",
    "We will start by importing ONNX of the trained CNN network into FINN and running the \"tidy-up\" transformations to have a first look at the topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import brevitas.onnx as bo\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/vgg_gray.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(build_dir + \"/vgg_gray_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is exported, let's have a look at its layer structure with Netron. Remember that the visualization below is interactive, you can click on the individual nodes and view the layer attributes, trained weights and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/workspace/finn/vgg_gray_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f617c269a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/vgg_gray_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the network is composed of a repeating convolution-maxpool layer pattern to extract features using 3x3 convolution kernels (with weights quantized) and activations, followed by a fully connected layer acting as the classifier. Also notice the initial `MultiThreshold` layer at the beginning of the network, which is quantizing float inputs to 8-bit ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Pre- and Postprocessing <a id='prepost'></a>\n",
    "\n",
    "Preprocessing and postprocessing steps can be added directly in the ONNX graph. In this case, the preprocessing step divides the input `uint8` data by 255 so the inputs to the CNN network are bounded between [0, 1]. The postprocessing step takes the output of the network and returns the index (0-9) of the image category with the highest probability (top-1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/transformation/infer_data_layouts.py:119: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(build_dir+\"/vgg_gray_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+\"/vgg_gray_preproc.onnx\"\n",
    "bo.export_finn_onnx(totensor_pyt, ishape, chkpt_preproc_name)\n",
    "\n",
    "# join preprocessing and core model\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# postprocessing: insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = build_dir+\"/vgg_gray_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/vgg_gray_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f615f0234f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/vgg_gray_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How FINN Implements Convolutions: Lowering and Streamlining\n",
    "\n",
    "In FINN, we implement convolutions with the *lowering* approach: we convert them to matrix-matrix multiply operations, where one of the matrices is generated by sliding a window over the input image. You can read more about the sliding window operator and how convolution lowering works [in this notebook](https://github.com/maltanar/qnn-inference-examples/blob/master/3-convolutional-binarized-gtsrb.ipynb). The streaming dataflow architecture we will end up with is going to look something like this figure from the [FINN-R paper](https://arxiv.org/abs/1809.04570).\n",
    "\n",
    "Note how the convolution layer looks very similar to the fully connected one in terms of the matrix-vector-threshold unit (MVTU), but now the MVTU is preceded by a sliding window unit that produces the matrix from the input image. All of these building blocks, including the `MaxPool` layer you see in this figure, exist as templated Vivado HLS C++ functions in [finn-hlslib](https://github.com/Xilinx/finn-hlslib).\n",
    "\n",
    "\n",
    "To target this kind of hardware architecture with our network we'll apply a convolution lowering transformation, in addition to streamlining. You may recall the *streamlining transformation* that we applied to the TFC-w1a1 network, which is a series of mathematical simplifications that allow us to get rid of floating point scaling operations by implementing few-bit activations as thresholding operations. **The current implementation of streamlining is highly network-specific and may not work for your network if its topology is very different than the example network here. We hope to rectify this in future releases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/vgg_gray_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + \"/vgg_gray_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into too much detail about what happens in each transformation and why they are called in the particular order they are (feel free to visualize the intermediate steps using Netron yourself if you are curious) but here is a brief summmmary:\n",
    "\n",
    "* `Streamline` moves floating point scaling and addition operations closer to the input of the nearest thresholding activation and absorbs them into thresholds\n",
    "* `LowerConvsToMatMul` converts ONNX `Conv` nodes into sequences of `Im2Col, MatMul` nodes as discussed above. `Im2Col` is a custom FINN ONNX high-level node type that implements the sliding window operator.\n",
    "* `MakeMaxPoolNHWC` and `AbsorbTransposeIntoMultiThreshold` convert the *data layout* of the network into the NHWC data layout that finn-hlslib primitives use. NCHW means the tensor dimensions are ordered as `(N : batch, H : height, W : width, C : channels)` (assuming 2D images). The ONNX standard ops normally use the NCHW layout, but the ONNX intermediate representation itself does not dictate any data layout.\n",
    "* You may recall `ConvertBipolarMatMulToXnorPopcount` from the TFC-w1a1 example, which is needed to implement bipolar-by-bipolar (w1a1) networks correctly using finn-hlslib.\n",
    "\n",
    "Let's visualize the streamlined and lowered network with Netron. Observe how all the `Conv` nodes have turned into pairs of `Im2Col, MatMul` nodes, and many nodes including `BatchNorm, Mul, Add` nodes have disappeared and replaced with `MultiThreshold` nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/vgg_gray_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f61641165b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir+\"/vgg_gray_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Partitioning, Conversion to HLS Layers and Folding\n",
    "\n",
    "The next steps will be (again) very similar to what we did for the TFC-w1a1 network. We'll first convert the layers that we can put into the FPGA into their HLS equivalents and separate them out into a *dataflow partition*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/custom_op/fpgadataflow/streamingfclayer_batch.py:591: UserWarning: Clipping some thresholds in StreamingFCLayer_Batch_MatMul_0\n",
      "  warnings.warn(\"Clipping some thresholds in %s\" % self.onnx_node.name)\n",
      "/workspace/finn/src/finn/custom_op/fpgadataflow/streamingfclayer_batch.py:591: UserWarning: Clipping some thresholds in StreamingFCLayer_Batch_MatMul_2\n",
      "  warnings.warn(\"Clipping some thresholds in %s\" % self.onnx_node.name)\n"
     ]
    }
   ],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/vgg_gray_streamlined.onnx\")\n",
    "model = model.transform(to_hls.InferBinaryStreamingFCLayer(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer(mem_mode))\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "# get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + \"/vgg_gray_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(build_dir + \"/vgg_gray_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the additional `RemoveCNVtoFCFlatten` transformation that was not used for TFC-w1a1. In the last Netron visualization you may have noticed a `Reshape` operation towards the end of the network where the convolutional part of the network ends and the fully-connected layers started. That `Reshape` is essentialy a tensor flattening operation, which we can remove for the purposes of hardware implementation. We can examine the contents of the dataflow partition with Netron, and observe the `ConvolutionInputGenerator`, `StreamingFCLayer_Batch` and `StreamingMaxPool_Batch` nodes that implement the sliding window, matrix multiply and maxpool operations in hlslib. *Note that the StreamingFCLayer instances following the ConvolutionInputGenerator nodes are really implementing the convolutions, despite the name. The final StreamingFCLayer instance implement an actual FC layer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/vgg_gray_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f617c213880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/vgg_gray_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pretty much everything has gone into the `StreamingDataflowPartition` node; the only operation remaining is to apply a `Transpose` to obtain NHWC input from a NCHW input (the ONNX default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/vgg_gray_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6055124fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/vgg_gray_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to set the *folding factors* for certain layers to adjust the performance of our accelerator, similar to the TFC-w1a1 example. We'll also set the desired FIFO depths around those layers, which are important to achieve full throughput in the accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/vgg_gray_dataflow_model.onnx\")\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# each tuple is (PE, SIMD, in_fifo_depth, ramstyle) for a layer\n",
    "folding = [\n",
    "    (8, 1, 32, \"auto\"),\n",
    "    (8, 16, 32, \"distributed\"),\n",
    "    (4, 16, 32, \"auto\"),\n",
    "    (1, 16, 32, \"auto\"),\n",
    "    (5, 1, 4, \"distributed\"),\n",
    "]\n",
    "for fcl, (pe, simd, ififodepth, ramstyle) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififodepth)\n",
    "    fcl_inst.set_nodeattr(\"ram_style\", ramstyle)\n",
    "\n",
    "# use same SIMD values for the sliding window operators\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "for i in range(len(swg_layers)):\n",
    "    swg_inst = getCustomOp(swg_layers[i])\n",
    "    simd = folding[i][1]\n",
    "    swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(build_dir + \"/vgg_gray_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualize in Netron to observe the `StreamingDataWidthConverter` and `StreamingFIFO` nodes that have been inserted into graph, as well as the folding factors in the `PE` and `SIMD` attributes of each `StreamingFCLayer_Batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/workspace/finn/vgg_gray_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f60550870a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/vgg_gray_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network is now ready and we can start with the hardware generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hardware Generation\n",
    "\n",
    "From this point onward, the steps we have to follow do not depend on the particular network and will be exactly the same as the TFC-w1a1 example. **which may take about 30 minutes depending on your host computer**. For more details about what's going on in this step, please consult the [TFC end-to-end notebook](tfc_end2end_example.ipynb) or the appropriate section in the [FINN documentation](https://finn.readthedocs.io/en/latest/hw_build.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 25 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:154: UserWarning: Overriding input FIFO depth to 32\n",
      "  warnings.warn(\"Overriding input FIFO depth to 32\")\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:201: UserWarning: Overriding output FIFO depth to 32\n",
      "  warnings.warn(\"Overriding output FIFO depth to 32\")\n"
     ]
    }
   ],
   "source": [
    "test_pynq_board = \"Pynq-Z2\"\n",
    "target_clk_ns = 10\n",
    "\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+\"/vgg_gray_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = test_pynq_board, period_ns = target_clk_ns))\n",
    "model.save(build_dir + \"/vgg_gray_synth.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deployment and Remote Execution\n",
    "\n",
    "Now that we're done with the hardware generation, we can generate a Python driver for accelerator and copy the necessary files onto our PYNQ board.\n",
    "\n",
    "**Make sure you've [set up the SSH keys for your PYNQ board](https://finn-dev.readthedocs.io/en/latest/getting_started.html#pynq-board-first-time-setup) before executing this step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to PYNQ Linux, based on Ubuntu 18.04 (GNU/Linux 5.4.0-xilinx-v2020.1 armv7l)\r\n",
      "\r\n",
      " * Super-optimized for small spaces - read how we shrank the memory\r\n",
      "   footprint of MicroK8s to make it the smallest full K8s around.\r\n",
      "\r\n",
      "   https://ubuntu.com/blog/microk8s-memory-optimisation\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# set up the following values according to your own environment\n",
    "# FINN will use ssh to deploy and run the generated accelerator\n",
    "ip = os.getenv(\"PYNQ_IP\", \"192.168.2.99\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/finn_cnv_end2end_example\")\n",
    "# set up ssh options to only allow publickey authentication\n",
    "options = \"-o PreferredAuthentications=publickey -o PasswordAuthentication=no\"\n",
    "\n",
    "# test access to PYNQ board\n",
    "! ssh {options} {username}@{ip} -p {port} cat /var/run/motd.dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/vgg_gray_synth.onnx\")\n",
    "model = model.transform(MakePYNQDriver(platform=\"zynq-iodma\"))\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(build_dir + \"/vgg_gray_pynq_deploy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xilinx/finn_dev_owner/pynq_deployment_njsd47ii'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dir_pynq = target_dir + \"/\" + model.get_metadata_prop(\"pynq_deployment_dir\").split(\"/\")[-1]\n",
    "target_dir_pynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4244\r\n",
      "-rw-rw-r-- 1 xilinx xilinx   20556 Jan 22 21:34 driver_base.py\r\n",
      "-rw-r--r-- 1 xilinx xilinx    5031 Jan 22 21:34 driver.py\r\n",
      "drwxr-xr-x 4 xilinx xilinx    4096 Jan 22 21:34 finn\r\n",
      "-rw-r--r-- 1 xilinx xilinx 4045671 Jan 22 21:34 resizer.bit\r\n",
      "-rw-r--r-- 1 xilinx xilinx  246855 Jan 22 21:34 resizer.hwh\r\n",
      "drwxr-xr-x 2 xilinx xilinx    4096 Jan 22 21:34 runtime_weights\r\n",
      "-rw-rw-r-- 1 xilinx xilinx    4113 Jan 22 21:34 validate.py\r\n"
     ]
    }
   ],
   "source": [
    "! ssh {options} {username}@{ip} -p {port} 'ls -l {target_dir_pynq}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two more steps to be able to remotely execute the deployed bitfile with some test data from the CIFAR-10 dataset. Let's load up some test data that comes bundled with FINN -- *and before you ask, that's supposed to be a cat (CIFAR-10 class number 3)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6150d2bd00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pkg_resources as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fn = pk.resource_filename(\"finn.qnn-data\", \"cifar10/cifar10-test-data-class3.npz\")\n",
    "x = np.load(fn)[\"arr_0\"]\n",
    "x = x.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we partitioned our original network into a parent graph that contained the non-synthesizable nodes and a child graph that contained the bulk of the network, which we turned into a bitfile. The only operator left outside the FPGA partition was a `Transpose` to convert NCHW images into NHWC ones. Thus, we can skip the execution in the parent as long as we ensure our image has the expected data layout, which we have done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6150c58760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "B, G, R = x.transpose(2, 0, 1).astype(\"uint32\")\n",
    "xx = ((B*3735+G*19235+R*9798)//(2**15)).reshape((32, 32, 1)).astype(\"uint8\")\n",
    "plt.imshow(xx, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/vgg_gray_pynq_deploy.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "oname = model.graph.output[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "input_dict = {iname: xx.astype(np.float32).reshape(ishape)}\n",
    "ret = execute_onnx(model, input_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[oname]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the network correctly predicts this as a class 3 (\"cat\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the Accuracy on a PYNQ Board <a id='validation'></a>\n",
    "\n",
    "All the command line prompts here are meant to be executed with `sudo` on the PYNQ board, so we'll use a workaround (`echo password | sudo -S command`) to get that working from this notebook running on the host computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for xilinx: Connection to 192.168.2.99 closed.\n"
     ]
    }
   ],
   "source": [
    "! ssh {options} -t {username}@{ip} -p {port} 'cd {target_dir_pynq}; echo {password} | sudo -S sed -i '\"'\"'75s/^/\\n    B,G,R=testx.transpose(3, 0, 1, 2).astype(\"uint32\");testx=((B*3735+G*19235+R*9798)\\/\\/(2**15)).reshape(testx.shape[:-1]+(1,)).astype(\"uint8\")/'\"'\"' validate.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `validate.py` script that was generated together with the driver to measure top-1 accuracy on the CIFAR-10 dataset.\n",
    "\n",
    "Command to execute on PYNQ:\n",
    "\n",
    "`python3.6 validate.py --dataset cifar10 --batchsize 1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for xilinx: Downloading Python CIFAR10 Data.\n",
      "Download URL: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Download DIR: /tmp\n",
      ">> Downloading cifar-10-python.tar.gz 100.0%\n",
      "Extracting Python CIFAR10 data.\n",
      "Files extracted\n",
      "batch 1 / 10 : total OK 857 NOK 143\n",
      "batch 2 / 10 : total OK 1695 NOK 305\n",
      "batch 3 / 10 : total OK 2540 NOK 460\n",
      "batch 4 / 10 : total OK 3377 NOK 623\n",
      "batch 5 / 10 : total OK 4233 NOK 767\n",
      "batch 6 / 10 : total OK 5068 NOK 932\n",
      "batch 7 / 10 : total OK 5920 NOK 1080\n",
      "batch 8 / 10 : total OK 6764 NOK 1236\n",
      "batch 9 / 10 : total OK 7586 NOK 1414\n",
      "batch 10 / 10 : total OK 8447 NOK 1553\n",
      "Final accuracy: 84.470000\n",
      "Connection to 192.168.2.99 closed.\n"
     ]
    }
   ],
   "source": [
    "! ssh {options} -t {username}@{ip} -p {port} 'cd {target_dir_pynq}; echo {password} | sudo -S python3.6 validate.py --dataset cifar10 --batchsize 1000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the final top-1 accuracy is 84.47%, which is very close to the 84.22% reported on the [BNN-PYNQ accuracy table in Brevitas](https://github.com/Xilinx/brevitas/tree/master/src/brevitas_examples/bnn_pynq). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
